global:
  smtp_smarthost: 'localhost:587'
  smtp_from: 'alertmanager@h200-mug-positioning.local'
  resolve_timeout: 5m

# Inhibition rules allow to mute a set of alerts given that another alert is firing
inhibit_rules:
  # Mute any warning-level notifications if the same alert is already critical
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'instance']

  # Mute instance down alerts if the entire service is down
  - source_match:
      alertname: 'ServiceDown'
    target_match:
      alertname: 'InstanceDown'
    equal: ['service']

route:
  group_by: ['alertname', 'service', 'severity']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  receiver: 'default'
  routes:
    # Critical alerts go immediately to all channels
    - match:
        severity: critical
      receiver: 'critical-alerts'
      group_wait: 10s
      repeat_interval: 30m
    
    # GPU-related alerts
    - match:
        category: gpu
      receiver: 'gpu-alerts'
      group_interval: 2m
      repeat_interval: 1h
    
    # Cost-related alerts
    - match:
        category: cost
      receiver: 'cost-alerts'
      group_interval: 10m
      repeat_interval: 24h
    
    # Performance alerts
    - match:
        category: performance
      receiver: 'performance-alerts'
      group_interval: 5m
      repeat_interval: 2h
    
    # Business logic alerts
    - match:
        category: business
      receiver: 'business-alerts'
      group_interval: 15m
      repeat_interval: 6h

receivers:
  - name: 'default'
    webhook_configs:
      - url: '${WEBHOOK_URL}/alerts'
        send_resolved: true
        http_config:
          bearer_token: '${WEBHOOK_TOKEN}'
        title: 'H200 Mug Positioning - {{ .Status | title }}'
        text: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Service: {{ .Labels.service }}
          Severity: {{ .Labels.severity }}
          {{ end }}

  - name: 'critical-alerts'
    webhook_configs:
      - url: '${WEBHOOK_URL}/alerts/critical'
        send_resolved: true
        http_config:
          bearer_token: '${WEBHOOK_TOKEN}'
        title: 'CRITICAL: H200 System Alert'
        text: |
          üö® CRITICAL ALERT üö®
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Service: {{ .Labels.service }}
          Instance: {{ .Labels.instance }}
          Started: {{ .StartsAt.Format "2006-01-02 15:04:05 UTC" }}
          {{ end }}
    
    # Also send to n8n webhook for additional processing
    - url: '${N8N_WEBHOOK_URL}/critical-alerts'
      send_resolved: true
      http_config:
        bearer_token: '${TEMPLATED_API_KEY}'

  - name: 'gpu-alerts'
    webhook_configs:
      - url: '${WEBHOOK_URL}/alerts/gpu'
        send_resolved: true
        http_config:
          bearer_token: '${WEBHOOK_TOKEN}'
        title: 'GPU Alert: H200 System'
        text: |
          üñ•Ô∏è GPU Alert
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          GPU Usage: {{ .Labels.gpu_utilization }}%
          Memory Usage: {{ .Labels.gpu_memory_usage }}%
          Temperature: {{ .Labels.gpu_temperature }}¬∞C
          {{ end }}

  - name: 'cost-alerts'
    webhook_configs:
      - url: '${WEBHOOK_URL}/alerts/cost'
        send_resolved: true
        http_config:
          bearer_token: '${WEBHOOK_TOKEN}'
        title: 'Cost Alert: H200 System'
        text: |
          üí∞ Cost Alert
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Current Rate: ${{ .Labels.cost_per_hour }}/hour
          Daily Projection: ${{ .Labels.daily_cost_projection }}
          {{ end }}

  - name: 'performance-alerts'
    webhook_configs:
      - url: '${WEBHOOK_URL}/alerts/performance'
        send_resolved: true
        http_config:
          bearer_token: '${WEBHOOK_TOKEN}'
        title: 'Performance Alert: H200 System'
        text: |
          ‚ö° Performance Alert
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Latency: {{ .Labels.latency }}ms
          Error Rate: {{ .Labels.error_rate }}%
          Throughput: {{ .Labels.requests_per_second }}/sec
          {{ end }}

  - name: 'business-alerts'
    webhook_configs:
      - url: '${WEBHOOK_URL}/alerts/business'
        send_resolved: true
        http_config:
          bearer_token: '${WEBHOOK_TOKEN}'
        title: 'Business Alert: H200 System'
        text: |
          üìä Business Alert
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Success Rate: {{ .Labels.success_rate }}%
          Cache Hit Rate: {{ .Labels.cache_hit_rate }}%
          Analyses/min: {{ .Labels.analyses_per_minute }}
          {{ end }}

# Global configuration for all notifications
templates:
  - '/etc/alertmanager/templates/*.tmpl'